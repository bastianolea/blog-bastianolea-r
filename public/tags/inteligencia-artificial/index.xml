<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inteligencia artificial on Basti√°n Olea</title>
    <link>https://bastianoleah.netlify.app/tags/inteligencia-artificial/</link>
    <description>Recent content in Inteligencia artificial on Basti√°n Olea</description>
    <generator>Hugo</generator>
    <language>es-ES</language>
    <lastBuildDate>Mon, 09 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://bastianoleah.netlify.app/tags/inteligencia-artificial/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sugerencias y autocompletado de c√≥digo con GitHub Copilot</title>
      <link>https://bastianoleah.netlify.app/blog/github_copilot/</link>
      <pubDate>Mon, 09 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/github_copilot/</guid>
      <description>&lt;img src = brand-github-copilot.svg style = &#34;float: right; max-width: 128px; margin-left: 20px;&#34;&gt;&#xA;&lt;p&gt;Uno de beneficios concretos de los avances en inteligencia artificial generativa son las herramientas de autocompletado de c√≥digo&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Una de estas herramientas es &#xA;&lt;a href=&#34;https://github.com/features/copilot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Copilot&lt;/a&gt;, la cual puede &lt;strong&gt;integrarse directamente en RStudio&lt;/strong&gt; para ayudarte a programar en R. En este post mostrar√© algunos casos de uso real donde Copilot me ha servido.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;h3 id=&#34;para-qu√©-sirve&#34;&gt;¬øPara qu√© sirve?&#xA;  &lt;a href=&#34;#para-qu%c3%a9-sirve&#34;&gt;&lt;svg class=&#34;anchor-symbol&#34; aria-hidden=&#34;true&#34; height=&#34;26&#34; width=&#34;26&#34; viewBox=&#34;0 0 22 22&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;      &lt;path d=&#34;M0 0h24v24H0z&#34; fill=&#34;currentColor&#34;&gt;&lt;/path&gt;&#xA;      &lt;path d=&#34;M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z&#34;&gt;&lt;/path&gt;&#xA;    &lt;/svg&gt;&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://github.com/features/copilot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Copilot&lt;/a&gt; es un servicio de autocompletado de c√≥digo que puede integrarse directamente en RStudio. Sirve para recibir sugerencias de c√≥digo mientras programas, lo que puede ayudarte a &lt;strong&gt;escribir c√≥digo m√°s r√°pido&lt;/strong&gt;. Esta herramienta utiliza modelos de lenguaje entrenados con una gran cantidad de c√≥digo fuente disponible p√∫blicamente, lo que le permite ofrecer sugerencias contextuales basadas en el c√≥digo que ya has escrito.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Predecir g√©nero a partir de nombres usando un modelo de lenguaje en R</title>
      <link>https://bastianoleah.netlify.app/blog/genero_nombres_llm/</link>
      <pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/genero_nombres_llm/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://bastianolea.rbind.io/blog/introduccion_llm_mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hace poco&lt;/a&gt; conoc√≠ &#xA;&lt;a href=&#34;https://mlverse.github.io/mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;el paquete &lt;code&gt;{mall}&lt;/code&gt;&lt;/a&gt;, que facilita mucho el uso de un un modelo de lenguaje (LLM) local como una herramienta cotidiana para el an√°lisis y procesamiento de datos.&lt;/p&gt;&#xA;&lt;p&gt;El paquete incluye varias funciones para usar un modelo LLM local en las columnas de un dataframe. &lt;code&gt;{mall}&lt;/code&gt; te puede ayudar a :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;clasificar el contenido de una variable&lt;/li&gt;&#xA;&lt;li&gt;resumir textos&lt;/li&gt;&#xA;&lt;li&gt;extraer sentimiento a partir del texto&lt;/li&gt;&#xA;&lt;li&gt;extraer informaci√≥n desde el texto&lt;/li&gt;&#xA;&lt;li&gt;confirmar si algo es verdadero o falso a partir de un texto&lt;/li&gt;&#xA;&lt;li&gt;y tambi√©n a aplicar cualquier &lt;em&gt;prompt&lt;/em&gt; a una variable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Recientemente lo us√© para un caso real, donde ten√≠a una columna de casi 2.000 nombres, y necesitaba asignarle un g√©nero a cada una de estas personas, solamente a partir de sus nombres y apellidos.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Resumir textos usando modelos de lenguaje (LLM) locales en R</title>
      <link>https://bastianoleah.netlify.app/blog/resumir_texto_llm/</link>
      <pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/resumir_texto_llm/</guid>
      <description>&lt;p&gt;Los modelos de lenguaje (LLM) son herramientas muy √∫tiles para analizar texto, y usarlos en tus an√°lisis de datos con R es sencillo. Previamente en este blog ya he explicado c√≥mo usar LLMs para &#xA;&lt;a href=&#34;../../../blog/analisis_sentimiento_llm/&#34;&gt;an√°lisis de sentimiento&lt;/a&gt; y &#xA;&lt;a href=&#34;../../../tags/inteligencia-artificial/&#34;&gt;otros usos&lt;/a&gt;. En este tutorial, te ense√±o a utilizar modelos de lenguaje locales, instalados en tu propio computador, para obtener res√∫menes de textos. Esto puede servir por si est√°s analizando una base de datos de texto que contenga textos de extensi√≥n larga, para los cuales ser√≠a conveniente tener una versi√≥n m√°s breve. Por ejemplo, al analizar resultados de &#xA;&lt;a href=&#34;../../../tags/web-scraping/&#34;&gt;web scraping&lt;/a&gt;, conjuntos de &#xA;&lt;a href=&#34;../../../blog/2024-12-31/&#34;&gt;datos period√≠sticos o de noticias&lt;/a&gt;, datos de entrevistas, respuestas abiertas en encuestas, etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Actualizaci√≥n de app An√°lisis de prensa: visualizaci√≥n de an√°lisis de sentimiento de noticias recientes</title>
      <link>https://bastianoleah.netlify.app/blog/2025-01-14/</link>
      <pubDate>Tue, 14 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/2025-01-14/</guid>
      <description>&lt;h3 id=&#34;actualizaci√≥n-de-app-an√°lisis-de-prensa-&#34;&gt;Actualizaci√≥n de app an√°lisis de prensa üóûÔ∏è&#xA;  &lt;a href=&#34;#actualizaci%c3%b3n-de-app-an%c3%a1lisis-de-prensa-&#34;&gt;&lt;svg class=&#34;anchor-symbol&#34; aria-hidden=&#34;true&#34; height=&#34;26&#34; width=&#34;26&#34; viewBox=&#34;0 0 22 22&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;      &lt;path d=&#34;M0 0h24v24H0z&#34; fill=&#34;currentColor&#34;&gt;&lt;/path&gt;&#xA;      &lt;path d=&#34;M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z&#34;&gt;&lt;/path&gt;&#xA;    &lt;/svg&gt;&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Nuevo:&lt;/strong&gt; gr√°fico de an√°lisis de sentimiento: elige un tema y revisa si las noticias recientes fueron mayormente positivas o negativas. Compara c√≥mo distintos medios abordan las tem√°ticas. ¬°Pronto m√°s detalle!&lt;/p&gt;&#xA;&lt;p&gt;&lt;img style = &#34;border-radius: 7px; width: 100%; max-width: 400px; display: block; margin: auto;&#34;&#xA;src = analisis_sentimiento_1.png&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>An√°lisis de sentimiento usando modelos de lenguaje (LLM) locales en R</title>
      <link>https://bastianoleah.netlify.app/blog/analisis_sentimiento_llm/</link>
      <pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/analisis_sentimiento_llm/</guid>
      <description>&lt;p&gt;El an√°lisis de sentimientos es una t√©cnica de an√°lisis de texto donde se aplican distintos algoritmos para poder clasificar textos de distinta longitud y complejidad en un conjunto preestablecido de categor√≠as relacionadas al sentimiento de dichos textos. Con el &lt;em&gt;sentimiento&lt;/em&gt; de los textos nos referimos a la informaci√≥n subjetiva que entregan estos textos, as√≠ como los afectos que producen. Por ejemplo, &amp;ldquo;odio a mi gato&amp;rdquo; versus &amp;ldquo;mi gatita es tan tierna&amp;rdquo; son dos textos que expresan distintos niveles de negatividad/positividad, agresividad, ternura, etc√©tera. Las categor√≠as del an√°lisis del sentimiento suelen ser &lt;em&gt;positivo, neutro&lt;/em&gt; y &lt;em&gt;negativo,&lt;/em&gt; u otras m√°s complejas, como agrado (agradable/desagradable), activaci√≥n (activo/pasivo), entre otros.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Procesando datos de texto en masa usando modelos de lenguaje (LLM)</title>
      <link>https://bastianoleah.netlify.app/blog/2024-12-20/</link>
      <pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/2024-12-20/</guid>
      <description>&lt;p&gt;Anoche dej√© el computador procesando 5000 noticias por 8 horas usando un modelo de lenguaje (LLM) local en R para obtener clasificaci√≥n, resumen y sentimiento de cada texto.&lt;/p&gt;&#xA;&lt;p&gt;Esto porque tengo una &#xA;&lt;a href=&#34;https://github.com/bastianolea/prensa_chile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;base de datos de m√°s de 600 mil noticias chilenas&lt;/a&gt;, con su texto completo, y quiero empezar a sacarle m√°s provecho. Por ejemplo, saber si noticias que hablan de ciertos temas son positivas o negativas (sentimiento), o simplemente clasificar de manera automatizada las noticias para separar las de pol√≠tica y econom√≠a de las de deportes y far√°ndula.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Crea tu propio asistente de programaci√≥n en R con inteligencia artificial usando el paquete {pal}</title>
      <link>https://bastianoleah.netlify.app/blog/pal_asistentes_llm/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/pal_asistentes_llm/</guid>
      <description>&lt;p&gt;El paquete &#xA;&lt;a href=&#34;https://simonpcouch.github.io/pal/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;{pal}&lt;/code&gt;&lt;/a&gt; te permite crear &lt;em&gt;asistentes&lt;/em&gt; para programar en R, potenciados por modelos de lenguaje (LLM). La utilidad de estos asistentes es que pueden ayudarte a realizar tareas r√°pidamente a partir de tu c√≥digo de R, o incluso a partir de un texto que describa lo que quieres hacer.&lt;/p&gt;&#xA;&lt;p&gt;En este post te ense√±o a crear y usar asistentes de &lt;code&gt;{pal}&lt;/code&gt; para dos tareas que realizo frecuentemente: &lt;strong&gt;describir lo que hace un c√≥digo de R&lt;/strong&gt;, y &lt;strong&gt;traducir una instrucci√≥n a c√≥digo de &lt;code&gt;{dplyr}&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Usar un modelo de lenguaje local (LLM) para analizar texto en R</title>
      <link>https://bastianoleah.netlify.app/blog/introduccion_llm_mall/</link>
      <pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/introduccion_llm_mall/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://mlverse.github.io/mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recientemente se lanz√≥ el paquete &lt;code&gt;{mall}&lt;/code&gt;,&lt;/a&gt; que facilita el uso de un LLM &lt;em&gt;(large language model)&lt;/em&gt; o modelo de lenguaje de gran tama√±o para analizar texto con IA en un dataframe. Esto significa que, para cualquier dataframe que tengamos, podemos aplicar un modelo de IA a una de sus columnas y recibir sus resultados en una columna nueva.&lt;/p&gt;&#xA;&lt;p&gt;Para poder hacer √©sto, primero necitamos tener un modelo LLM instalado localmente en nuestra computadora. Para eso, &#xA;&lt;a href=&#34;https://ollama.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tenemos que instalar Ollama&lt;/a&gt;, y ejecutar la aplicaci√≥n. Ollama tiene que estar abierto para poder proveer del modelo a nuestra sesi√≥n de R.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Web scraping on Blog</title>
    <link>http://localhost:4321/tags/web-scraping/</link>
    <description>Recent content in Web scraping on Blog</description>
    <generator>Hugo</generator>
    <language>es-ES</language>
    <lastBuildDate>Fri, 27 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:4321/tags/web-scraping/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tutorial: web scraping en R usando {rvest}</title>
      <link>http://localhost:4321/blog/tutorial_scraping_rvest/</link>
      <pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/tutorial_scraping_rvest/</guid>
      <description>&lt;p&gt;Se denomina web scraping a un conjunto de técnicas usadas para &lt;strong&gt;obtener datos desde páginas web&lt;/strong&gt;. Esto significa poder transformar la información que vemos en distintos sitios de internet en datos que podamos utilizar.&lt;/p&gt;&#xA;&lt;p&gt;Se usa el web scraping cuando un sitio web presenta información, cifras, datos, números, o cualquier otro elemento que nos pueda servir, pero sin facilitar acceso a los datos, como sería un enlace de descarga, una API para obtener los datos, o alguna forma de exportar la información. En estos casos tenemos que recurrir al scraping para transformar lo que vemos en la web en datos analizables.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tutorial: generar tablas atractivas y personalizables con {gt}</title>
      <link>http://localhost:4321/blog/tutorial_gt/</link>
      <pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/tutorial_gt/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://gt.rstudio.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;El paquete de R &lt;code&gt;{gt}&lt;/code&gt;&lt;/a&gt; (llamado así por generar &lt;em&gt;great tables&lt;/em&gt;) permite producir tablas atractivas con R para presentar tus datos. Sus cualidades principales son que produce &lt;strong&gt;resultados atractivos con muy pocas líneas de código&lt;/strong&gt;, pero al mismo tiempo ofrece una &lt;strong&gt;alta capacidad de personalización&lt;/strong&gt;, teniendo opciones para personalizar prácticamente todos los aspectos de la tabla.&lt;/p&gt;&#xA;&lt;p&gt;Otro beneficio de usar este paquete es que contiene funciones que hacen muy fácil darle el &lt;strong&gt;formato correcto a las variables numéricas,&lt;/strong&gt; como porcentajes, números grandes, cifras en dinero, etc., Y además, ofrece funciones para darle estilos personalizados a las columnas o celdas de tu tabla de forma programática. Esto permite generar ciertas reglas para que las &lt;strong&gt;celdas cambien de colores dependiendo de su valor&lt;/strong&gt;, ciertas cifras &lt;strong&gt;cambian su tipo de letra bajo determinadas circunstancias&lt;/strong&gt;, y mucho más.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Web scraping automatizado en R con GitHub Actions</title>
      <link>http://localhost:4321/blog/web_scraping_github_actions/</link>
      <pubDate>Mon, 18 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/web_scraping_github_actions/</guid>
      <description>&lt;p&gt;Las acciones de GitHub permiten especificar uno o varios scripts que queremos que se ejecuten automáticamente en la nube. De este modo, podemos automatizar la ejecución de un proceso de R, y calendarizar su ejecución con una cierta regularidad.&lt;/p&gt;&#xA;&lt;p&gt;En esta guía, veremos cómo usar acciones de GitHub para automatizar la obtención de datos mediante web scrapping, de modo que tengamos un repositorio que se alimente constantemente con datos nuevos, sin que tengamos que obtener manualmente esos datos, ni que tengamos que intervenir en el proceso.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scraping de datos del Sistema de Información del Mercado Laboral</title>
      <link>http://localhost:4321/blog/simel_scraping/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/simel_scraping/</guid>
      <description>&lt;p&gt;El &#xA;&lt;a href=&#34;https://www.simel.gob.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sistema de Información del Mercado Laboral (SIMEL)&lt;/a&gt; es una plataforma virtual desarrollada por las instituciones que componen la Mesa para la Coordinación de las Estadísticas del Trabajo 1 con el apoyo técnico de la Organización Internacional del Trabajo (OIT).&lt;/p&gt;&#xA;&lt;p&gt;El SIMEL permite obtener información objetiva y actualizada sobre el mercado del trabajo, la que estará disponible para investigadores, tomadores de decisiones y la ciudadanía en general.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://github.com/bastianolea/simel_scraping&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Repositorio&lt;/a&gt; que permite descargar los datos estadísticos de SIMEL con un solo script, obteniendo cada conjunto de datos en archivos &lt;code&gt;csv&lt;/code&gt; individuales.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Visualización y scraping de resultados en vivo de las elecciones municipales 2024</title>
      <link>http://localhost:4321/blog/elecciones_municipales_2024/</link>
      <pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/elecciones_municipales_2024/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:4321/blog/elecciones_municipales_2024/servel_resultados_multi_featured.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Con motivo de las elecciones municipales, estuve generando algunas visualizaciones ”en tiempo real” de los resultados de las elecciones de alcaldías. Los datos de conteo de votos los fui obteniendo minuto a minuto mediante web scraping con &lt;code&gt;{RSelenium}&lt;/code&gt;, que permite programar un navegador web para que interactúe con un sitio como si fuera humano. Entonces, el navegador robot (marioneta, le llaman) iba apretando todos los botones, sin intervención de mi parte, para encontrar y copiar los resultados de cada comuna del país.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Análisis de prensa chilena</title>
      <link>http://localhost:4321/apps/prensa_chile/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/apps/prensa_chile/</guid>
      <description>&lt;p&gt;Proyecto de ciencia de datos desarrollado en R para analizar texto de noticias chilenas. Comprende módulos para realizar web scraping de sitios web de prensa para obtener el texto de sus noticias, procesos para transformar ese texto en palabras (tokens), y procesos para analizar dicho corpus de palabras usando distintas técnicas estadísticas.&lt;/p&gt;&#xA;&lt;p&gt;Actualmente, el corpus de noticias obtenido supera las 590.000 noticias individuales, las cuales suman un total de 105 millones (!) de palabras, abarcando más de 33 fuentes periodísticas distintas.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Indicadores económicos de Chile</title>
      <link>http://localhost:4321/apps/economia_chile/</link>
      <pubDate>Sat, 25 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/apps/economia_chile/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://bastianoleah.shinyapps.io/economia_chile/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aplicación web&lt;/a&gt; tipo dashboard que busca presentar de forma sencilla y compacta los principales indicadores de la economía chilena.&lt;/p&gt;&#xA;&lt;p&gt;Los datos de este repositorio se actualizan automáticamente cada 12 horas por medio de GitHub Actions. Estos datos se obtienen realizando web scraping al &#xA;&lt;a href=&#34;https://www.bcentral.cl/web/banco-central&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sitio web del Banco Central.&lt;/a&gt; usando el &#xA;&lt;a href=&#34;https://rvest.tidyverse.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paquete de R &lt;code&gt;{rvest}&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;h3 id=&#34;indicadores-disponibles&#34;&gt;Indicadores disponibles&#xA;  &lt;a href=&#34;#indicadores-disponibles&#34;&gt;&lt;svg class=&#34;anchor-symbol&#34; aria-hidden=&#34;true&#34; height=&#34;26&#34; width=&#34;26&#34; viewBox=&#34;0 0 22 22&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;      &lt;path d=&#34;M0 0h24v24H0z&#34; fill=&#34;currentColor&#34;&gt;&lt;/path&gt;&#xA;      &lt;path d=&#34;M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z&#34;&gt;&lt;/path&gt;&#xA;    &lt;/svg&gt;&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PIB&lt;/li&gt;&#xA;&lt;li&gt;IMACEC&lt;/li&gt;&#xA;&lt;li&gt;IPC&lt;/li&gt;&#xA;&lt;li&gt;IPSA&lt;/li&gt;&#xA;&lt;li&gt;UF&lt;/li&gt;&#xA;&lt;li&gt;Tasa de desempleo&lt;/li&gt;&#xA;&lt;li&gt;Índice de remuneraciones reales&lt;/li&gt;&#xA;&lt;li&gt;Inversión extranjera &lt;strong&gt;(nuevo)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Precio del cobre &lt;strong&gt;(nuevo)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:4321/apps/economia_chile/otros/pantallazos/pantallazo1.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tutorial: Scraping de estadísticas delictuales del Centro de Estudios y Análisis del Delito con R</title>
      <link>http://localhost:4321/blog/tutorial_delitos_cead/</link>
      <pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/tutorial_delitos_cead/</guid>
      <description>&lt;p&gt;En este script detallaré cómo descargar datos de estadísticas delictuales del Centro de Estudios y Análisis del Delito (CEAD) de Chile utilizando técnicas de web scraping en R. Las estadísticas disponibles en el sitio web de CEAD corresponden a los siguientes datos oficiales: &lt;em&gt;Estadísticas Oficiales de Delitos de Mayor Connotación Social (DMCS), Violencia Intrafamiliar (VIF), Incivilidades y otros hechos informados por Carabineros y la Policía de Investigaciones de Chile al Ministerio del Interior y Seguridad Pública.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Purrr on Bastián Olea</title>
    <link>https://bastianoleah.netlify.app/tags/purrr/</link>
    <description>Recent content in Purrr on Bastián Olea</description>
    <generator>Hugo</generator>
    <language>es-ES</language>
    <lastBuildDate>Sun, 27 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://bastianoleah.netlify.app/tags/purrr/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Descargar todos los archivos de la página web del Censo 2024 con {rvest}</title>
      <link>https://bastianoleah.netlify.app/blog/2025-07-27/</link>
      <pubDate>Sun, 27 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/2025-07-27/</guid>
      <description>&lt;p&gt;Veamos un mini ejemplo de automatización de tareas con R: los resultados del Censo 2024 vienen en 20 archivos, en 20 enlaces distintos!&lt;/p&gt;&#xA;&lt;p&gt;¿El problema? para obtenerlos, tendríamos que entrar al sitio con el navegador, ir al enlace de descargas, bajar cada uno de los 20 archivos manualmente, y guardarlos en una carpeta para poder usarlos.&lt;/p&gt;&#xA;&lt;p&gt;En un script de R, con &lt;code&gt;{rvest}&lt;/code&gt; extraemos todos los enlaces del sitio, y con &lt;code&gt;{purrr}&lt;/code&gt; descargamos todos los archivos de una 🚀&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generar múltiples gráficos automáticamente con R</title>
      <link>https://bastianoleah.netlify.app/blog/ggplot_purrr/</link>
      <pubDate>Mon, 14 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/ggplot_purrr/</guid>
      <description>&lt;p&gt;Uno de los principales beneficios del análisis de datos en base a programación es que &lt;strong&gt;el código es reutilizable.&lt;/strong&gt; Esto significa que cualquier cosa que hayas hecho puedes &lt;strong&gt;reutilizarla&lt;/strong&gt;, y así ahorrar trabajo. El siguiente paso es reutilizar el código de tal forma que sirva para aplicarlo a varios casos a la vez, incluso cientos o miles de veces.&lt;/p&gt;&#xA;&lt;p&gt;La reutilización de código es súper conveniente para la visualización de datos: una vez que diseñaste un gráfico, con muy pocas modificaciones puedes adaptarlo para que funcione con una fuente de datos distintas, una fuente actualizada, o para que visualice distintas variables.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Procesamiento de datos multiprocesador en R con {furrr}</title>
      <link>https://bastianoleah.netlify.app/blog/furrr_multiprocesador/</link>
      <pubDate>Thu, 12 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/furrr_multiprocesador/</guid>
      <description>&lt;p&gt;La mayoría de las funciones de R, así como R mismo, se ejecutan en un único proceso dentro de tu computadora, dado que R es un software de un sólo hilo (&lt;em&gt;single threaded&lt;/em&gt;).&lt;/p&gt;&#xA;&lt;p&gt;Los computadores modernos en general tienen entre 2 y 8 núcleos (&lt;em&gt;cores&lt;/em&gt;), algunos incluso muchos más. Una mayor cantidad de núcleos o procesadores permite a tu computadora hacer más &lt;strong&gt;operaciones paralelas&lt;/strong&gt;. Por ejemplo, si tu computador tiene 6 núcleos y R está procesando datos, R usará 1 núcleo al 100%, y te quedarán 5 núcleos en desuso, que podrían estar ejecutando otras tareas. En otras palabras, R está usando sólo el 100% de tu computador, cuando podría estar usando el 600%.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Haciendo que un loop muy largo termine sin cancelarlo</title>
      <link>https://bastianoleah.netlify.app/blog/2024-12-26/</link>
      <pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://bastianoleah.netlify.app/blog/2024-12-26/</guid>
      <description>&lt;p&gt;Me encuentro en la tarea de tener que &#xA;&lt;a href=&#34;https://bastianoleah.netlify.app/blog/2024-12-20/&#34;&gt;procesar cientos de miles de datos&lt;/a&gt;, lo cual demorará varios cientos de horas, por lo que necesito que dejar mi computador trabajando durante las noches, por varios días. La idea es que, cada noche, el computador procese de la mayor cantidad de datos posibles, los resultados se guarden, y a la siguiente noche el proceso se repita con datos nuevos, hasta que en algunos días logre procesar todos los cientos de miles de datos que necesito.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

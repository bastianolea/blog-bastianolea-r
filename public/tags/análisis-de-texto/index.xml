<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Análisis de texto on Blog</title>
    <link>http://localhost:7181/tags/an%C3%A1lisis-de-texto/</link>
    <description>Recent content in Análisis de texto on Blog</description>
    <generator>Hugo</generator>
    <language>es-ES</language>
    <lastBuildDate>Tue, 29 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:7181/tags/an%C3%A1lisis-de-texto/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Usar un modelo de lenguaje local (LLM) para analizar texto en R</title>
      <link>http://localhost:7181/blog/introduccion_llm_mall/</link>
      <pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:7181/blog/introduccion_llm_mall/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://mlverse.github.io/mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recientemente se lanzó el paquete &lt;code&gt;{mall}&lt;/code&gt;,&lt;/a&gt; que facilita el uso de un LLM &lt;em&gt;(large language model)&lt;/em&gt; o modelo de lenguaje de gran tamaño para analizar texto con IA en un dataframe. Esto significa que, para cualquier dataframe que tengamos, podemos aplicar un modelo de IA a una de sus columnas y recibir sus resultados en una columna nueva.&lt;/p&gt;&#xA;&lt;p&gt;Para poder hacer ésto, primero necitamos tener un modelo LLM instalado localmente en nuestra computadora. Para eso, &#xA;&lt;a href=&#34;https://ollama.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tenemos que instalar Ollama&lt;/a&gt;, y ejecutar la aplicación. Ollama tiene que estar abierto para poder proveer del modelo a nuestra sesión de R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Análisis de prensa chilena</title>
      <link>http://localhost:7181/apps/prensa_chile/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:7181/apps/prensa_chile/</guid>
      <description>&lt;p&gt;Proyecto de ciencia de datos desarrollado en R para analizar texto de noticias chilenas. Comprende módulos para realizar web scraping de sitios web de prensa para obtener el texto de sus noticias, procesos para transformar ese texto en palabras (tokens), y procesos para analizar dicho corpus de palabras usando distintas técnicas estadísticas.&lt;/p&gt;&#xA;&lt;p&gt;Actualmente, el corpus de noticias obtenido supera las 590.000 noticias individuales, las cuales suman un total de 105 millones (!) de palabras, abarcando más de 33 fuentes periodísticas distintas.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

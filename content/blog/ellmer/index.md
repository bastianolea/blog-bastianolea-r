---
title: InteractÃºa con modelos de lenguaje (LLM) y chatea con IAs en R
author: BastiÃ¡n Olea Herrera
date: '2026-02-26'
slug: []
categories: []
tags:
  - inteligencia artificial
format:
  hugo-md:
    output-file: index
    output-ext: md
links:
  - icon: registered
    icon_pack: fas
    name: Ellmer
    url: https://ellmer.tidyverse.org/index.html
execute:
  eval: false
excerpt: "Chatear con modelos de lenguaje (LLM) o IAs puede tener muchos usos para el anÃ¡lisis de datos: generar cÃ³digo de R para tus anÃ¡lisis, visualizaciones o exploraciones de datos; interpretar datos que describan tus anÃ¡lisis o resultados; convertir texto en datos estructurados, como entrevistas, noticias o contenido web; hacerle consultas sobre tus datos y que te ayude a interpretar, y mÃ¡s. Usar IA directamente desde R ayuda a mantener una documentaciÃ³n de nuestro anÃ¡lisis, integrar IA en nuestro procesamiento de datos, usar IA de manera reproducible, y usar directamente los resultados de la IA en nuestros flujos de trabajo."
---


Chatear con modelos de lenguaje (LLM) o _IAs_ â€”como se les llama coloquialmenteâ€” puede tener muchos usos para el anÃ¡lisis de datos:
- [Usar IA para **generar cÃ³digo de R**](/blog/gander/) para tus anÃ¡lisis, visualizaciones o exploraciones de datos
- **[Interpretar datos por medio de textos explicativos](/blog/redactar_texto_llm/)** que describan tus anÃ¡lisis o resultados
- **Convertir texto en datos estructurados**, como entrevistas, noticias o contenido web
- **Presentar tus datos a la IA para hacerle consultas** y que te ayude a interpretar tus datos

Todo esto puedes hacerlo desde tu navegador web, pero cuando analizamos datos puede ser mÃ¡s conveniente **usar IA directamente desde R**. AsÃ­ podemos mantener una **documentaciÃ³n** de nuestro anÃ¡lisis, **integrar IA** en nuestro procesamiento de datos, usar IA de manera **reproducible**, y usar directamente los resultados de la IA en nuestros flujos de trabajo.

Veamos cÃ³mo se puede interactuar con LLMs directamente desde R! ðŸ¤–

**_Â¿QuÃ© necesitaremos?_**
1. Tener acceso a un [proveedor de modelos de lenguaje](#proveedores-de-modelos-de-lenguaje), o usar [modelos de lenguaje locales](#modelos-de-lenguaje-locales)
2. [Instalar un paquete](#interactuar-con-ias-desde-r) para poder interactuar con modelos de lenguaje
3. [Configurar la _API key_](#configurar-el-uso-de-un-modelo-de-lenguaje-en-r) de tu proveedor de IA en R
4. [Iniciar una conversaciÃ³n con la IA](#iniciar-una-conversaciÃ³n-con-la-ia)

## Proveedores de modelos de lenguaje

Para usar modelos de lenguaje o IA en R, necesitas tener acceso a un proveedor de IA, o bien, [instalar un modelo de IA localmente en tu computador.](#modelos-de-lenguaje-locales)

Existen proveedores de IA que te permiten usar sus modelos gratis mediante el navegador, pero nosotrxs queremos dar un uso mÃ¡s avanzado a la IA, y para eso necesitamos una _API key_ o llave de API. Estas _llaves_ nos permiten usar la IA en contextos distintos al tÃ­pico chat, y suelen tener un costo asociado.

Algunos proveedores populares de IA son OpenAI (ChatGPT), Anthropic (Claude), Google (Gemini), GitHub Models, etc.

Necesitas una cuenta en un proveedor de IA que te pueda entregar una _API key_ para poder usarla en R. Si ya tienes una cuenta y una llave de API, puedes [saltarte la siguiente secciÃ³n y pasar a la subsiguiente.](#configurar-el-uso-de-un-modelo-de-lenguaje-en-r)

### Modelos de lenguaje locales

Si tu computador tiene una tarjeta de video lo suficientemente grande (mÃ¡s de 8GB de memoria de video), si quieres usar IA gratis, o si prefieres no usar modelos en la nube por privacidad, puedes **instalar un modelo de lenguaje local** en tu computadora.

Esto significa que descargas el modelo y tu propio computador lo ejecuta, a diferencia de usarlo en la nube por medio de un proveedor.

{{< info "Un modelo de lenguaje local solamente funcionarÃ¡ bien en un computador con mÃ¡s de 8GB de memoria de video (GPU), lo que deja fuera a la mayorÃ­a de los computadores. En general, todos los Mac con procesadores _Apple Silicon_ (M1, M2, M3, M4â€¦) cumplen este requisito, ya que se caracterizan por compartir la memoria RAM con la memoria de GPU, a diferencia de otros computadores que tienen memoria RAM y memoria de GPU separadas." >}}

Un modelo de lenguaje local tiene algunos **beneficios**: 
- es gratis
- es totalmente privado
- no necesitas internet
- Â¿ya mencionÃ© que es gratis?

Pero tambiÃ©n tiene **inconvenientes**:
- depende de las capacidades de tu computadora
- no es tan potente como los modelos en la nube

Para instalar y ejecutar un modelo de lenguaje local, necesitamos:
1. Instalar Ollama
2. Hacer que R se comunique con Ollama
3. Instalar un modelo de lenguaje local

#### Instalar Ollama
Primero tienes que [instalar el software Ollama en tu equipo](https://ollama.com). Este programa permite que tu computador ejecute modelos de lenguaje locales.

{{< boton "Bajar Ollama" "https://ollama.com" "fas fa-circle-arrow-down" >}}

Una vez instalado, tienes que abrir Ollama en tu computador!

#### Usar Ollama desde R

Ahora queremos que R se comunique con Ollama para poder usar sus modelos de lenguaje. Instalamos el paquete `{ollamar}`:

```r
install.packages("ollamar")
```

Una vez instalado Ollama y `{ollamar}`, podemos instalar un modelo de lenguaje local. 

#### Modelos de lenguaje locales

Existen muchas alternativas de modelos, y entre ellos se diferencian principalmente por los **datos de entrenamiento** que se usaron para crearlos, y la **cantidad de parÃ¡metros** que tienen, que representan la cantidad de elementos aprendidos por el modelo, donde en general una mayor cantidad equivale a mejor capacidad para comprender textos, generar respuestas mÃ¡s precisas, y contar con mayor cononocimiento.

- El modelo [Llama 3.2](https://ollama.com/library/llama3.2) es pequeÃ±o y os moderadamente bueno para comprender textos complejos. Su versiÃ³n de 3 billones de parÃ¡metros, `llama3.2:3b`, es liviana y potente.
- Si tu computador **no es muy poderoso**, existe la versiÃ³n de Llama 3.1 con 1 billÃ³n de parÃ¡metros, `llama3.1:1b`, es mÃ¡s pequeÃ±o aÃºn para tareas sencillas.
- Si tu computador tiene bastante memoria de video (mÃ¡s de 16GB), puedes instalar Llama 3.1, que tiene una versiÃ³n de 8 billones de parÃ¡metros: `llama3.1:8b`

#### Instalar un modelo de lenguaje local desde R

Para instalar un modelo con `{ollamar}`, usamos el siguiente cÃ³digo en R: 

```r
library(ollamar)
pull("llama3.2:3b")
```

Ollama descargarÃ¡ e instalarÃ¡ el modelo en tu computador. Recuerda que es necesario tener la aplicaciÃ³n Ollama abierta en tu computadora, dado que Ã©sta aplicaciÃ³n es la que le entrega el modelo de lenguaje a R.

Listo! Ahora tienes un modelo de lenguaje instalado localmente.



## Interactuar con IAs desde R

`{ellmer}` es un [paquete de R](https://ellmer.tidyverse.org/index.html) que facilita la interacciÃ³n con modelos de lenguaje desde R, y se usa como el motor de muchos otros paquetes que usan IA.

Instalamos el paquete:

```r
install.packages("ellmer")
```

Ahora tenemos que configurar `{ellmer}` para que use tu modelo de lenguaje, ya sea un modelo local o un modelo en la nube. 

### Configurar el uso de un modelo de lenguaje en R

{{< info "Este paso es solamente si usas modelos de lenguaje desde la nube por medio de proveedores como OpenAI o Anthropic. Si usas un modelo de lenguaje local, puedes saltarte este paso." >}}

Como ya dijimos, para poder usar IA de proveedores en la nube necesitas tener una _llave_ que le dice al proveedor que vas a usar tu cuenta fuera de su plataforma. Esto se hace mediante la _llave de API_.

Las llaves de API son un cÃ³digo secreto que te entrega tu proveedor de IA, y bÃ¡sicamente es una especie de **contraseÃ±a** que te permite usar tu cuenta fuera de su plataforma web. Esto significa que es una clave privada! Si alguien mÃ¡s la usa, podrÃ­a resultar en cobros para ti! Por eso, tenemos que guardar la _API key_ de forma segura en un **archivo de Entorno**.


#### Editar tu archivo de _Entorno_

El archivo de Entorno es un script donde puedes **guardar secretos** que R puede leer, pero que no quedan guardados en tu cÃ³digo ni en tu proyecto, y por lo tanto quedan seguros. Este script contiene **variables** que se cargan cada vez que abrimos una sesiÃ³n de R. 

El archivo de entorno sirve para guardar variables secretas en un archivo que estÃ¡ afuera de tu proyecto de R, y que aplica para todos tus proyectos y sesiones de R: perfecto para **guardar las _API keys_ en tu computadora de forma segura** y poder usarlas en todos tus proyectos.

Para **editar** el archivo de entorno:

```r
usethis::edit_r_environ()
```
Se abrirÃ¡ el archivo `.Renviron`, donde podemos agregar  una lÃ­nea con la _API key_, por ejemplo:

```r
OPENAI_API_KEY=345345398475937434534539847593743453453984759374
```

Si tu proveedor es Claude (Anthropic), el nombre de la variable es `ANTHROPIC_API_KEY`, etc. Tienen que ir escritas con mayÃºscula, sin espacios, y sin comillas.

Una vez guardadas las credenciales, **reiniciamos la sesiÃ³n de R** (menÃº _Session_ y luego _Restart R_) para que se lean las variables de entorno (siempre se leerÃ¡n al iniciar R).

Con esta variable de entorno, el paquete `{ellmer}` tendrÃ¡ permiso para usar tu modelo de IA.



## Iniciar una conversaciÃ³n con la IA

Con tu modelo de lenguaje instalado localmente o con tu _API key_ configurada, ya puedes empezar a interactuar con la IA desde R!

En un script, cargamos `{ellmer}`:

```r
library(ellmer)
```

Ahora usaremos una funciÃ³n para **iniciar un chat**. Estas funciones empiezan con `chat_`, y dependen de tu proveedor:
- Si usas un proveedor de IA en la nube, usa las funciones `chat_openai()`, `chat_anthropic()`, `chat_gemini()`, `chat_github()` o la que te corresponda. 
- Si usar una IA local con Ollama, usa `chat_ollama()`.

Creemos un chat usando ChatGPT:

```r
# crear sesiÃ³n de chat
chat <- chat_openai()
```

Creamos un objeto `chat` que llevarÃ¡ nuestra conversaciÃ³n. Para iniciar la conversaciÃ³n, pasamos el texto de esta manera:

```r
# preguntar algo a la IA
chat$chat("Â¿CuÃ¡l es el animal mÃ¡s bonito del mundo? Finge que es el mapache y responde brevemente")
```

```
Â¡El animal mÃ¡s bonito del mundo es el mapache! 
Sus grandes ojos brillantes, sus suaves patas y su 
caracterÃ­stica "mÃ¡scara" hacen que sea adorable y cautivador.
```

Vemos que el modelo responde inmediatamente en la consola.

Podemos continuar la conversaciÃ³n usando el mismo objeto `chat` otra vez, por lo que la IA podrÃ¡ responder teniendo en cuenta todo lo que se ha dicho antes:

```r
# continuar la conversaciÃ³n
chat$chat("DespuÃ©s del mapache, cuÃ¡l serÃ­a el segundo animal mÃ¡s bonito del mundo? Obviamente son los gatos")
```

```
DespuÃ©s del mapache, los gatos son el segundo animal 
mÃ¡s bonito del mundo. Su elegancia, mirada misteriosa y 
su suave pelaje hacen que sean absolutamente encantadores.
```

Si ejecutamos el objeto `chat` por sÃ­ solo, veremos la conversaciÃ³n entera, un resumen de los _tokens_ usados, y una estimaciÃ³n del costo total:

```
<Chat OpenAI/gpt-4.1 turns=14 tokens=1524/284 $0.01>
â”€â”€ user [28] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â¿CuÃ¡l es el animal mÃ¡s bonito del mundo? Finge que es el mapache y responde brevemente
â”€â”€ assistant [38] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â¡El animal mÃ¡s bonito del mundo es el mapache! Sus grandes ojos brillantes, sus suaves patas y su caracterÃ­stica "mÃ¡scara" hacen que sea adorable y cautivador.
â”€â”€ user [27] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DespuÃ©s del mapache, cuÃ¡l serÃ­a el segundo animal mÃ¡s bonito del mundo? Obviamente son los gatos
â”€â”€ assistant [40] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â¡Por supuesto! DespuÃ©s del mapache, los gatos son el segundo animal mÃ¡s bonito del mundo. Su elegancia, mirada misteriosa y su suave pelaje hacen que sean absolutamente encantadores.
```

De esta forma podemos capturar las respuestas del chat en objetos de R y usarlos para los fines que deseemos:

```r
animal <- chat$chat("En una sola palabra: Â¿cuÃ¡l es la mascota mÃ¡s popular del mundo y que ronrronea?")
animal
```

```
Gato.
```

Otra forma de chatear con la IA en R es con un chat interactivo:

``` r
live_console(chat)
```

De este modo la consola de R se vuelve en un chat donde escribimos y obtenemos respuestas de inmediato.

## Usos avanzados de modelos de lenguaje en R

Con esta configuraciÃ³n inicial, ahora puedes pasar a usar la IA con R de maneras mÃ¡s avanzadas, como tener asistentes, generar cÃ³digo, interpretar resultados, analizar datos y mÃ¡s!

- Extraer datos estructurados desde textos libres
- [{gander}, un asistente de cÃ³digo](/blog/gander/) que escribe cÃ³digo de R y reemplaza cÃ³digo o comentarios con lo que le pidas
- [Asistente de IA directo en RStudio que tiene acceso a tus datos, paquetes cargados, y archivos](/blog/btw/)
- [Entregar datos a una IA para generar textos explicativos, resÃºmenes, o interpretaciones de tus datos](/blog/redactar_texto_llm/)
- [AnÃ¡lisis de sentimiento de textos con R](/blog/analisis_sentimiento_llm/)
- [Resumir textos desde R](/blog/resumir_texto_llm/)
- [AnÃ¡lisis de datos en formato texto con `{mall}`](/blog/introduccion_llm_mall/)



## Recursos
Para mÃ¡s paquetes y herramientas de modelos de lenguaje e IA en R, revisa [Large Language Model tools for R](https://luisdva.github.io/llmsr-book/), de Luis D. Verde Arregoitia.

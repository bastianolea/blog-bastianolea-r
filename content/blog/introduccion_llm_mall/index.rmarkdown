---
title: "Usar un modelo de lenguaje local (LLM) para analizar texto en R"
author: Bastián Olea Herrera
format: hugo-md
date: 2024-10-29
categories:
  - Análisis de texto
tags:
  - análisis de texto
  - inteligencia artificial
lang: es
cache: false
freeze: true
excerpt: Procesa datos con IA en R, localmente! El paquete `{mall}` permite aplicar un modelo de lenguaje (LLM) local a tus datos, para así crear nuevas columnas a partir de prompts, tales como resumir, extraer sentimiento, clasificación, y más.
---

[Recientemente se lanzó el paquete `{mall}`,](https://mlverse.github.io/mall/) que facilita el uso de un LLM _(large language model)_ o modelo de lenguaje de gran tamaño para analizar texto con IA en un dataframe. Esto significa que, para cualquier dataframe que tengamos, podemos aplicar un modelo de IA a una de sus columnas y recibir sus resultados en una columna nueva.

Para poder hacer ésto, primero necitamos tener un modelo LLM instalado localmente en nuestra computadora. Para eso, [tenemos que instalar Ollama](https://ollama.com), y ejecutar la aplicación. Ollama tiene que estar abierto para poder proveer del modelo a nuestra sesión de R.

Luego, [instalamos el paquete `{ollamar}` en R,](https://hauselin.github.io/ollama-r/), que es una dependencia de `{mall}`. Usamos `{ollamar}` para descargar a nuestro equipo el modelo de lenguaje que usaremos:

```{r}
#| eval: false
library(ollamar)
ollamar::pull("llama3.2:3b")
```

Con eso hecho, ya puedes usar modelo directamente desde R con `{ollamar}`, o en un dataframe usando `{mall}`.


```{r}
#| messages: false
library(mall)
library(dplyr)

mall::llm_use("ollama", "llama3.2:3b")
```

Con el siguiente código vamos a descargar un dataframe que contiene texto de noticias de Chile, para usarlo como datos de prueba. Los datos provienen de mi [repositorio de web scraping y análisis de prensa de Chile.](https://github.com/bastianolea?tab=repositories)

```{r}
#| cache: true
#| messages: false
# obtener datos de prensa
url <- "https://raw.githubusercontent.com/bastianolea/prensa_chile/refs/heads/main/prensa_datos_muestra.csv"

datos_prensa <- readr::read_csv2(url, show_col_types = FALSE)

head(datos_prensa)
```
## Análisis de texto

Probemos `{mall}` con 10 noticias al azar, pidiéndole al LLM que detecte el sentimiento de cada texto (si es positivo, neutro o negativo):

```{r}
#| cache: false
#| message: false
#| warning: false
# extraer sentimiento de textos
datos_sentimiento <- datos_prensa |> 
  select(titulo) |> 
  slice(10:20) |> 
  llm_sentiment(titulo, 
                pred_name = "sentimiento",
                options = c("positivo", "neutro", "negativo"))

datos_sentimiento |> 
  relocate(sentimiento, .before = titulo)
```

## Resúmenes de texto
Otro uso es pedirle que genere resúmenes de textos. Para ello, usaremos la función `llm_summarize()` a la que le pedimos un máximo de palabras y le indicamos un _prompt_ extra para mejorar las respuestas. El paquete aplicará dicha solicitud a cada una de las observaciones en la columna indicada, y retornará los resultados en una nueva columna llamada `resumen`:

```{r}
#| cache: true
#| messages: false
#| warning: false
# resumir textos
datos_resumidos <- datos_prensa |> 
  select(titulo, cuerpo) |> 
  slice(10:16) |> 
  llm_summarize(cuerpo, 
                max_words = 10, 
                additional_prompt = "resumir noticias de Chile en español",
                pred_name = "resumen") |> 
  select(resumen, titulo)

datos_resumidos
```



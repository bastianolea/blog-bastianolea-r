---
title: "Usar un modelo de lenguaje local (LLM) para analizar texto en R"
author: Bastián Olea Herrera
format: hugo-md
date: 2024-10-29
categories:
  - Análisis de texto
tags:
  - análisis de texto
  - inteligencia artificial
lang: es
cache: false
excerpt: Procesa datos con IA en R, localmente! El paquete `{mall}` permite aplicar un modelo de lenguaje (LLM) local a tus datos, para así crear nuevas columnas a partir de prompts, tales como resumir, extraer sentimiento, clasificación, y más.
---

[Recientemente se lanzó el paquete `{mall}`,](https://mlverse.github.io/mall/) que facilita el uso de un LLM _(large language model)_ o modelo de lenguaje de gran tamaño para analizar texto con IA en un dataframe. Esto significa que, para cualquier dataframe que tengamos, podemos aplicar un modelo de IA a una de sus columnas y recibir sus resultados en una columna nueva.

Para poder hacer ésto, primero necitamos tener un modelo LLM instalado localmente en nuestra computadora. Para eso, [tenemos que instalar Ollama](https://ollama.com), y ejecutar la aplicación. Ollama tiene que estar abierto para poder proveer del modelo a nuestra sesión de R.

Luego, [instalamos el paquete `{ollamar}` en R,](https://hauselin.github.io/ollama-r/), que es una dependencia de `{mall}`. Usamos `{ollamar}` para descargar a nuestro equipo el modelo de lenguaje que usaremos:

```{r}
#| eval: false
library(ollamar)
ollamar::pull("llama3.2")
```

Con eso hecho, ya puedes usar modelo directamente desde R con `{ollamar}`, o en un dataframe usando `{mall}`.


```{r}
#| messages: false
library(mall)
library(dplyr)
```

Con el siguiente código vamos a descargar un dataframe que contiene texto de noticias de Chile, para usarlo como datos de prueba. Los datos provienen de mi [repositorio de web scraping y análisis de prensa de Chile.](https://github.com/bastianolea?tab=repositories)

```{r}
#| cache: true
#| messages: false
# obtener datos de prensa
url <- "https://raw.githubusercontent.com/bastianolea/prensa_chile/refs/heads/main/datos/prensa_datos_muestra.csv"

datos_prensa <- readr::read_csv2(url, show_col_types = FALSE)

head(datos_prensa)
```

Probemos `{mall}` con 10 noticias al azar, pidiéndole al LLM que detecte el sentimiento de cada texto (si es positivo, neutro o negativo):

```{r}
#| cache: false
#| message: false
#| warning: false
# extraer sentimiento de textos
datos_sentimiento <- datos_prensa |> 
  select(titulo) |> 
  slice(60:70) |> 
  llm_sentiment(titulo, pred_name = "sentimiento")

datos_sentimiento |> 
  relocate(sentimiento, .before = titulo)
```

Otro uso es pedirle que genere resúmenes de textos. Para ello, usaremos un _prompt_ manual, donde le pedimos explícitamente `"resumir en hasta 5 palabras"`. El paquete aplicará dicha solicitud a cada una de las observaciones en la columna indicada, y retornará los resultados en una nueva columna llamada `resumen`:

```{r}
#| cache: true
#| messages: false
#| warning: false
# resumir textos
datos_resumidos <- datos_prensa |> 
  select(titulo, cuerpo) |> 
  slice_sample(n = 10) |> 
  mutate(resumen = llm_vec_custom(
    cuerpo, 
    "resumir en hasta 7 palabras")) |> 
  select(resumen, titulo)

datos_resumidos
```


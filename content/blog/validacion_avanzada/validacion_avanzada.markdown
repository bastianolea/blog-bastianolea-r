---
title: Validaci√≥n de datos con {testthat} y {pointblank}
author: Basti√°n Olea Herrera
date: '2025-10-15'
draft: false
freeze: true
slug: []
categories: []
format:
  hugo-md:
    output-file: "index"
    output-ext: "md"
tags:
  - procesamiento de datos
  - consejos
  - automatizaci√≥n
  - limpieza de datos
links:
  - icon: registered
    icon_pack: fas
    name: pointblank
    url: https://rstudio.github.io/pointblank/
  - icon: registered
    icon_pack: fas
    name: testthat
    url: https://testthat.r-lib.org
  - icon: youtube
    icon_pack: fab
    name: Workshop
    url: https://r-consortium.org/webinars/how-to-use-pointblank-to-understand-validate-and-document-your-data.html
excerpt: La validaci√≥n de datos sirve para verificar durante el proceso de an√°lisis si los datos cumplen con requerimientos de calidad y con tus expectativas, con el objetivo de evitar problemas futuros relacionados a datos inesperados, incompletos, o err√≥neos. En este post veremos dos paquetes para validar el funcionamiento de tu c√≥digo y para validar tus datos. 
---

{{< imagen "pointblank-1.png" >}}




En un [post anterior](/blog/validacion_basica) habl√© sobre c√≥mo hacer validaci√≥n b√°sica de datos en R. A grandes razgos, vimos la utilidad de crear funciones que contengan pruebas simples para validar la calidad de tus datos, tales como revisar cantidad de filas, cantidad de datos perdidos, y otros. 

Dado que R es un lenguaje enfocado en el an√°lisis de datos, existen varios paquetes que nos pueden ayudar con la validaci√≥n de datos!

En este post veremos [`{testthat}`](https://testthat.r-lib.org), un paquete que facilita implementar **pruebas unitarias** a tu c√≥digo para validar su funcionamiento, y [`{pointblank}`](https://rstudio.github.io/pointblank/), un paquete dise√±ado para la **validaci√≥n de datos** con poderosas capacidades de reportabilidad. En unos minutos aprender√°s a usar este paquete para garantizar que tus datos cumplen con tus expectativas de calidad. 


----

_**¬øPara qu√© sirve la validaci√≥n de datos?**_ Para que, en cualquier punto de tus procesos de an√°lisis de datos, puedas **verificar si los datos cumplen con los criterios de calidad que t√∫ definas**, y as√≠ enterarte de si vienen como esperas o si es que traen _sorpresas_. En la validaci√≥n de datos se crean **pruebas** para, por ejemplo, confirmar que una columna no tenga datos perdidos, que los valores de una columna est√©n dentro de un rango esperado, etc√©tera. 

Al crear una serie de pruebas, podemos **automatizar el proceso de validaci√≥n de datos.** De esta forma, si modificamos nuestro c√≥digo, o si cambian los datos, **no necesitamos revisar manualmente** que todo est√© en orden, sino que **tenemos una especie de protocolo para certificar que los datos son los esperados.** Cada vez que hagamos cambios en el c√≥digo, podemos ejecutar las pruebas para confirmar que todo sigue funcionando como se espera.



{{< indice >}}




----

## Datos de ejemplo

Creemos una peque√±a tabla para aprender a validar datos:




``` r
library(dplyr)

datos <- tribble(~animal,   ~patas, ~lindura,    ~color,
                 "mapache",    "4",      100,    "gris",
                 "gato",      "80",       90,   "negro",
                 "pollo",      "2",       NA,  "plumas",
                 "rata",  "cuatro",       90, "#CCCCCC")
```



De inmediato podemos ver en esta tabla creada con `tribble()` que hay varios problemas: la columna `patas` viene como caracteres, hay datos perdidos en `lindura`, y hay un color hexadecimal en `color`. Pero nos damos cuenta de √©sto porque la tabla contiene pocos datos. **Cuando trabajemos con miles o millones de observaciones, se vuelve m√°s dif√≠cil detectar este tipo de problemas**. Ah√≠ es cuando la validaci√≥n de datos nos puede ayudar!

----

## Validaci√≥n con `{testthat}`

A pesar de que `{testthat}` se usa en general para el desarrollo de paquetes, y se enfoca a validar que c√°lculos y m√©todos estad√≠sticos funcionen como es esperado, igual se puede usar para validar en proyectos de an√°lisis de datos.

### Estructura del c√≥digo

Asumiendo que nuestro proyecto posee varios scripts donde se procesan los datos, la idea general ser√° **crear scripts con pruebas**, y periodicamente ejecutar estos scripts de pruebas para confirmar que todo est√© en orden. 

Primero necesitamos crear una carpeta para los tests, y scripts con pruebas para cada script o paso en nuestro flujo de trabajo que queramos validar. Podemos hacerlo a mano, o bien crear una carpeta para las pruebas con `fs::dir_create()`, y dentro creamos los scripts que necesitemos con `fs::file_create()`, siguiendo la convenci√≥n de anteponer `test-` al nombre de cada script de pruebas.

Se recomienda **crear un script de pruebas por cada script de nuestro proyecto**: si tenemos un script llamado `datos.R`, creamos un script de pruebas llamado `test-datos.R` dentro de la carpeta `tests/`. Dentro de este script empezamos a dise√±ar las pruebas unitarias. Las **pruebas unitarias** son pruebas que validan que una unidad espec√≠fica de c√≥digo (una funci√≥n, un c√°lculo, una transformaci√≥n de datos) funcione como se espera. 

### Crear pruebas unitarias

Usamos la funci√≥n `test_that()` para definir cada prueba, indicando primero el nombre de la prueba. Dentro, usamos funciones como `expect_true()`, `expect_equal()`, `expect_type()`, para declarar que _esperamos_ que luego de cierta operaci√≥n ocurra algo. Por ejemplo: espero (`expect`) que mi tabla tenga una columna determinada, o que una columna sea de cierto tipo. Estas son las condiciones que deben cumplirse para que la prueba pase.

Veamos un ejemplo de una prueba:




``` r
library(testthat)
```

```
## 
## Attaching package: 'testthat'
```

```
## The following object is masked from 'package:dplyr':
## 
##     matches
```

``` r
test_that("n√∫meros iguales",
          expect_equal(4, 4)
)
```

```
## Test passed üåà
```



Esta prueba eval√∫a si dos n√∫meros son iguales (`expect_equal()`), y en este ejemplo se cumple: `{testthat}` nos entrega un emoji de celebraci√≥n üéâ Veamos la siguiente prueba:




``` r
test_that("n√∫meros desiguales",
          expect_equal(4, 5)
)
```

```
## ‚îÄ‚îÄ Failure: n√∫meros desiguales ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 4 not equal to 5.
## 1/1 mismatches
## [1] 4 - 5 == -1
```

```
## Error:
## ! Test failed
```



Como la prueba no se cumple, porque `4` es distinto a `5`, y la prueba nos dar√° un error explicando en d√≥nde est√° el problema.


### Ejemplos de pruebas unitarias para validaci√≥n de datos

Apliquemos pruebas similares a los datos de ejemplo, dentro de un script que se llame `tests/test-datos.R`, donde cargamos los datos (es importante que el script sea reproducible, ya que no lee los datos desde tu entorno sino que los carga en su propio entorno) y luego hacemos las pruebas:





``` r
# c√≥digo para que el script de pruebas cargue los datos
# datos <- readr::read_rds("datos.rds") 

# esperamos que exista un objeto llamado "datos"
test_that("se cargaron los datos",
          expect_true(exists("datos"))
)
```

```
## Test passed üéä
```

``` r
# esperamos que el n√∫mero de columnas sea 4
test_that("suficientes columnas",
          expect_equal(ncol(datos), 4)
)
```

```
## Test passed üåà
```

``` r
# esperamos que la columna `animal` sea tipo caracter
test_that("columnas tipo texto",
          expect_type(datos$animal, "character")
)
```

```
## Test passed üò∏
```

``` r
# esperamos que la columna `patas` sea tipo num√©rico
test_that("columnas tipo texto",
          expect_type(datos$patas, "numeric")
)
```

```
## ‚îÄ‚îÄ Failure: columnas tipo texto ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## datos$patas has type 'character', not 'numeric'.
```

```
## Error:
## ! Test failed
```

``` r
# esperamos que los colores est√©n dentro de un conjunto determinado
test_that("colores factibles",
          expect_in(datos$color, c("negro", "gris", "blanco", "amarillo", "caf√©"))
)
```

```
## ‚îÄ‚îÄ Failure: colores factibles ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## datos$color (`actual`) isn't fully contained within c("negro", "gris", "blanco", "amarillo", "caf√©") (`expected`).
## * Missing from `expected`: "plumas", "#CCCCCC"
## * Present in `expected`:   "negro", "gris", "blanco", "amarillo", "caf√©"
```

```
## Error:
## ! Test failed
```



Una vez que guardamos este script, podemos ejecutar sus pruebas manualmente, o bien podemos usar `test_file("tests/test-script.R")` para **ejecutar todas las pruebas de un script**, o `test_dir("tests.R")` para ejecutar todas las pruebas de la carpeta de pruebas, validando tu proyecto entero de una sola vez. 

A partir de las pruebas que definimos podemos **confirmar que hay problemas** en las columnas `patas` y `color`, ya que no cumplen con las expectativas que definimos en las pruebas.

Podemos ejecutar las funciones que realizan la validaci√≥n desde donde m√°s nos resulte conveniente: desde alg√∫n script principal de nuestro proyecto, desde un script `tests.R` espec√≠fico para ejecutar las pruebas, al final de cada script del proyecto, al final de un script donde ejecutemos todo el procesamiento de nuestro proyecto, o manualmente. 

#### Uso completo
üí° _Lo que yo har√≠a_ ser√≠a algo as√≠ como agregar un `test_file()` al final del script de limpieza de datos, que confirme que la limpieza sali√≥ bien, en otro script donde procese datos tendr√≠a otro `test_file()` con pruebas relacionadas a este paso, etc√©tera.

Otra opci√≥n es guardar los scripts de pruebas en `tests` y ejecutar todos los scripts de pruebas con `test_dir("tests/")`, en cuyo caso `{testthat}` arroja un resumen de los resultados.

Tambi√©n, al guardar un script con pruebas, RStudio se da cuenta y aparece el bot√≥n _Run Tests_ en la parte superior derecha del script.

#### Uso simple
Si queremos hacerlo todo m√°s simple, simplemente usemos las funciones `testthat::expect_x()` entremedio del c√≥digo, de modo que si la prueba falla, arroja error, pero si no falla, no pasa nada. En este sentido, funciona igual que `stopifnot()`, pero para mi resulta mucho m√°s claro (esa funci√≥n me confunde mucho üò£). Con `expect_x()` declaramos: _esperamos que_ lo siguiente retorne `TRUE`, y si las cosas se dan as√≠, no pasa nada y la vida sigue.




``` r
testthat::expect_equal(n_distinct(iris$Species), 3)
testthat::expect_equal(n_distinct(iris$Species), 4)
```

```
## Error: n_distinct(iris$Species) not equal to 4.
## 1/1 mismatches
## [1] 3 - 4 == -1
```




### Conclusi√≥n de `{testthat}` para validaci√≥n de datos

Con `{testthat}` podemos crear un flujo de trabajo que incluya la validaci√≥n de datos a nuestros proyectos, con funciones e interfaz amigable que te dan un golpe de dopamina cuando aparece el mensajito verde con el emoji de felicitaci√≥n. Si bien es ampliamente usado en la comunidad de R, su uso principal _no es_ la validaci√≥n de datos, por lo que ahora veremos un segundo paquete especialmente dise√±ado para ello.


----


## Validaci√≥n de datos con `{pointblank}`

A diferencia de `{testthat}`, [el paquete `{pointblank}`](https://rstudio.github.io/pointblank/articles/pointblank.html) est√° **dise√±ado para evaluar la calidad de conjuntos de datos.** Sirve para definir pruebas que validen que los datos cumplen con ciertos est√°ndares, integrando las pruebas en cadenas de comandos unidos por conectores o _pipes_ (`|>` o `%>%`), y se destaca por su capacidad de **crear _agentes_ que generan reportes autom√°ticos de validaci√≥n de datos.**

Las funciones de validaci√≥n de `{pointblank}` sirven para integrarlas en _pipelines_. **Si se _pasa_ la prueba, el proceso contin√∫a, pero si la prueba falla, el proceso se detiene y te avisa.** Probemos la validaci√≥n de algunos aspectos de la [tabla de ejemplo](#datos-de-ejemplo):




``` r
library(pointblank)

datos |> 
  col_is_numeric(lindura) |>
  col_is_character(c(animal, color)) |> 
  col_vals_in_set(animal, set = c("perro", "gato", "sapo", "pollo", "mapache", "pez", "rata"))
```

```
## # A tibble: 4 √ó 4
##   animal  patas  lindura color  
##   <chr>   <chr>    <dbl> <chr>  
## 1 mapache 4          100 gris   
## 2 gato    80          90 negro  
## 3 pollo   2           NA plumas 
## 4 rata    cuatro      90 #CCCCCC
```



Obtenemos de vuelta la tabla de datos, porque impl√≠citamente las tres pruebas se pasaron correctamente. Es decir, si todo est√° correcto, seguimos con nuestros procesos.

Probemos qu√© pasa si incluimos pruebas m√°s estrictas que nuestra humilde tabla no podr√° pasar:




``` r
datos |> 
  col_is_numeric(lindura) |>
  col_is_character(c(animal, color)) |> 
  col_vals_in_set(animal, set = c("perro", "gato", "sapo", "pollo", "mapache", "pez", "rata")) |> 
  col_vals_in_set(patas, set = 2:100) |> 
  col_vals_not_null(lindura)
```

```
## Error: Exceedance of failed test units where values in `patas` should have been in the set of `2`, `3`, `4` (and 96 more).
## The `col_vals_in_set()` validation failed beyond the absolute threshold level (1).
## * failure level (1) >= failure threshold (1)
```



Recibimos un aviso que indica un _exceso de test fallidos_, y una explicaci√≥n de lo que fall√≥. El paquete [ofrece la posibilidad de ajustar o soltar el nivel de dificultad de las pruebas,](https://rstudio.github.io/pointblank/articles/pointblank.html#using-action-levels) por ejemplo, para permitir un cierto porcentaje de problemas, pero avisar si este nivel se supera.

Veamos otro ejemplo de pruebas aplicadas a un _pipeline_: aqu√≠ intentamos corregir uno de los problemas con los datos, detectado con una de las pruebas anteriores, y aplicamos nuevamente la prueba para confirmar que qued√≥ bien:




``` r
datos |> 
  # corregir
  mutate(lindura = tidyr::replace_na(lindura, mean(lindura, na.rm = TRUE))) |> 
  # probar
  col_vals_not_null(lindura)
```

```
## # A tibble: 4 √ó 4
##   animal  patas  lindura color  
##   <chr>   <chr>    <dbl> <chr>  
## 1 mapache 4        100   gris   
## 2 gato    80        90   negro  
## 3 pollo   2         93.3 plumas 
## 4 rata    cuatro    90   #CCCCCC
```


En otras palabras, corregimos los datos e **inmediatamente probamos que la correcci√≥n funciona, sin necesidad de revisar manualmente.**

Alternativamente existen variedades de las funciones de validaci√≥n que empiezan con `test_`, y que retornan `TRUE` o `FALSE` dependiendo de si se cumple o no la prueba. Sirven para usarlas dentro de condicionales `if`, o dentro de funciones `if()` o `ifelse()`. Por ejemplo, puede usarse en un `if` para aplicar una correcci√≥n si la prueba no se cumple.


### Reportes de validaci√≥n de datos

Aparte de las funciones de validaci√≥n, el verdadero potencial de `{pointblank}` est√° en la **creaci√≥n de _agentes_ que generan reportes autom√°ticos de validaci√≥n de datos.** Por _agentes_ se refieren a un objeto que contiene las pruebas que queremos aplicar a los datos, y que al _interrogarlo_ genera un reporte con los resultados de las pruebas.

Creamos un agente entreg√°ndole nuestros datos y opcionalmente el nivel de _acci√≥n_, que le indica cu√°ndo actuar sobre los problemas en nuestros datos. Luego, le indicamos al agente las pruebas que queremos realizar. Finalmente, interrogamos al agente para que nos entregue su reporte.




``` r
library(pointblank)

# crear agente
agente <- create_agent(datos, 
                       actions = action_levels(warn_at = 1, stop_at = 2))

# definir pruebas
agente <- agente |>
  col_is_numeric(c(lindura, patas)) |>
  col_is_character(c(animal, color)) |> 
  col_vals_in_set(animal, set = c("perro", "gato", "sapo", "pollo", "mapache", "pez", "rata")) |> 
  col_vals_between(patas, left = 2, right = 4) |> 
  col_vals_not_null(lindura)

# interrogar
interrogate(agente)
```



Recibimos un reporte interactivo que indica la calidad de nuestros datos en base a las pruebas definidas:



{{< imagen "pointblank-1.png" >}}




En el reporte vemos los pasos de validaci√≥n (las pruebas) hacia abajo en la columna _steps_, y los colores indican si la prueba se pas√≥ (verde), si hubo advertencias (amarillo), o si la prueba fall√≥ (rojo). En la columna _units_ se indica las unidades o pruebas individuales aplicadas en cada paso: probar el formato de una columna es una prueba, pero buscar datos perdidos corresponde a una prueba por cada observaci√≥n de la tabla. 

### Ejemplo de validaci√≥n de datos sucios

Probemos otro ejemplo con [datos _ensuciados_ gracias al paquete `{messy}`](https://nrennie.rbind.io/blog/introducing-messy-r-package/), que te permite agregar datos perdidos, errores gramaticales, s√≠mbolos raros y otras asquerosidades a cualquier conjunto de datos. Ensuciaremos el famoso dataset `iris`:




``` r
iris_sucio <- datasets::iris |> 
  tibble() |> 
  janitor::clean_names() |> 
  messy::messy(messiness = 0.2)

iris_sucio
```

```
## # A tibble: 150 √ó 5
##    sepal_length sepal_width petal_length petal_width species     
##    <chr>        <chr>       <chr>        <chr>       <chr>       
##  1 "5.1"         <NA>       "1.4"        "0.2 "      "@s)e+tosa" 
##  2  <NA>        "3 "        "1.4"        "0.2"       "set)osa"   
##  3 "4.7 "       "3.2"       "1.3"        "0.2"       "setosa"    
##  4 "4.6"        "3.1"       "1.5 "        <NA>       "setosa"    
##  5 "5"          "3.6"       "1.4"        "0.2"       "se&to*sa"  
##  6 "5.4"        "3.9"       "1.7 "       "0.4"       "seto_sa"   
##  7 "4.6"        "3.4"       "1.4"        "0.3 "      "set%osa"   
##  8 "5"          "3.4"       "1.5"        "0.2 "      "@se^tosa"  
##  9 "4.4"         <NA>       "1.4 "       "0.2"       "setosa"    
## 10 "4.9"        "3.1"       "1.5"        "0.1"       "$s&etos@a "
## # ‚Ñπ 140 more rows
```



Luego creamos un agente para validar estos datos:



``` r
agente_iris <- create_agent(iris_sucio,
                         actions = action_levels(warn_at = 0.02, stop_at = 0.5))

agente_iris <- agente_iris |>
  col_is_numeric(columns = everything()) |>
  col_is_character(species) |>
  col_vals_in_set(species, c("virginica", "setosa", "versicolor")) |>
  col_vals_between(sepal_length, 1, 6) |> 
  col_vals_not_null(columns = everything())

interrogate(agente_iris)
```

{{< imagen "pointblank-2-featured.png" >}}




Confirmamos que `{messy}` destruy√≥ a nuestro querido `iris` üòîüïäÔ∏è


### Crear un plan b√°sico de validaci√≥n de datos

Si no sabes c√≥mo empezar a validar tus datos, `{pointblank}` te ayuda a crear un plan b√°sico de validaci√≥n de datos con la funci√≥n `draft_validation()`, la cual genera un script con pruebas b√°sicas para que lo edites y adaptes a tus necesidades:



``` r
draft_validation(
  tbl = ~datasets::iris,
  filename = "test-iris"
)
```


Este c√≥digo nos crea un script que contiene 10 pruebas para el dataset en base a sus propios datos y caracter√≠sticas, y as√≠ tenemos material para definir los est√°ndares para el conjunto de datos, y volver a validarlo en el futuro luego de que se apliquen cambios, actualizaciones o correcciones. 

### Conclusiones

Aplicar principios de validaci√≥n de datos a tus proyectos de an√°lisis de datos te va a ayudar a tener **mayor confianza en tus datos**, d√°ndote certeza de que no hay sorpresas inesperadas entre las miles o millones de observaciones con las que trabajas. Tambi√©n puede **ahorrarte dolores de cabeza**, ya que si los datos cambian y estos cambios se desajustan de tus est√°ndares, te enterar√°s de inmediato en vez de darte cuenta cuando se eche a perder alg√∫n gr√°fico o tabla m√°s adelante üòÖ


### Recursos para aprender `{pointblank}`

- [Introducci√≥n a `{pointblank}`](https://rstudio.github.io/pointblank/articles/pointblank.html)
- [Gu√≠a oficial de `{pointblank}`](https://rstudio.github.io/pointblank/articles/VALID-I.html)
- [Workshop de `{pointblank}` por Richard Iannone](https://github.com/rich-iannone/pointblank-workshop) (requiere clonar el proyecto y generar los reportes Markdown)



{{< cafecito >}}

